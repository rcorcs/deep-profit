
\section{Related Work}

\subsection{Function Merging}

Link-time code optimizers like~\cite{tallam10,kwan12,msvc-icf} merge text-identical functions at the bit level.
However, such solutions are target-specific and need to be adapted for each object code format and hardware architecture.

GCC and LLVM~\cite{llvm-fm,livska14} also provide an optimization for merging identical functions at the IR level and hence is agnostic to the target hardware.
Unfortunately, they can only merge fully identical functions with at most type mismatches that can be losslessly cast to the same format.
The work presented by von Koch~et~al.~\cite{edler14} advanced this simple merging strategy by exploiting the CFG isomorphism of two
functions. However, it requires two mergeable functions to have identical CFGs and function types, where the two functions can only differ
between correspoding instructions, specifically, in their opcodes or the number and types of the input operands.
The state-of-the-art technique, FMSA~\cite{rocha19}, lifts most of the restrictions imposed by prior techniques~\cite{llvm-fm,livska14,edler14}.
Although achieving impressive results, it does not directly handle \textit{phi-nodes} which are fundamental to the SSA form.
In order to simplify their code generator, Rocha~et~al.~\cite{rocha19} replaced all phi-nodes with memory operations by first applying register demotion.
This tends to almost double the function size, increasing compilation time and hindering function merging, as it expects that applying register promotion to the merged function will reverse the negative effect of the earlier register demotion.
This is often not possible because function merging can add complexity to the memory operations, resulting in unnecessarily larger merged functions.

In order to avoid register demotion, Rocha~et~al.~\cite{rocha20} describes a novel approach, called SalSSA, for merging functions which is capable of effectively handling the SSA form.
Their approach achieves this with a new code generator that, instead of translating the aligned sequences directly into a merged function, generates code from the input control-flow graphs, using the alignment only to specify pairs of matching labels and instructions.
SalSSA then produces code top-down, starting with the control flow graph of the merged function, then populating with instructions, arguments and labels, and finally with phi-nodes which maintain the correct flow of data.

\subsection{Tuning Compilers with Deep Learning}

There is been many work using machine learning as a heuristic for tuning runtime systems~\cite{andreasson02,wang09,castro11,rocha17,pereira17} and compilers~\cite{cavazos05,leather09,cummins17,wang18,mendis19}.

Cavazos and O'Boyle~\cite{cavazos05} propose the use of genetic algorithm to tune the heuristics of function inlining.
They use genetic algorithm to optimise the values for different features that control the inlining heuristic.
%Some of these features are the size of the callee and caller functions.
These features are chosen by the compiler writer and they define the maximum size allowed by the inlining transformation for the callee and the caller functions, the maximum size for callee functions that are hot or that should always be inlined, etc.
The optimised features are then used to define the rules of the inlining heuristic, describing which call sites should be allowed for inlining.
The fitness function of the genetic algorithm involves the actual runtime of the compiled program, rendering the feature optimisation process very costly.
However, their approach is able to achieve significant speedups over the baseline.

The quality of these features is critical to the improvements resulting from machine learning solutions.
Leather~et~al.~\cite{leather09} propose the use of genetic programming in order to also automate the selection of these features.
The feature space is described by a grammar and is then searched with genetic programming and predictive modelling, to avoid recompilation of the program for each step in searching the optimization space.
The genetic programming technique is used to generate features that are fed to a decision tree.
This machine learning solution form the decision-making heuristics for the loop-unrolling optimisation.
They show that the automated selection of features outperform hand-coded features, for the same machine learning procedure based on decision trees.

Cummins~et~al.~\cite{cummins17} propose DeepTune, which uses deep neural networks to learn optimization heuristics directly on raw code, unifying the search for features and decision-making heuristics into a single learning model.
Since the program, in its textual form, can be seen as a sequence of tokens of variable length, using a recurrent neural networks becomes a natural choice.
DeepTune has an LSTM-based language model that processes raw code, producing a fixed-size encoding which is then fed to a heuristic model based on a feed-forward neural network.

Mendis~et~al.~\cite{mendis19} propose Ithemal, a tool which uses deep neural networks to predict the throughput of a set of machine instructions.
Ithemal can be used as a cost model for compiler optimisations and code generation, aiding the decision of whether a transformation would result in faster code.
Similar to DeepTune, Ithemal also processes raw machine instructions using an LSTM-based language model.
However, Ithemal has an architecture with two LSTM stages.
The first LSTM processes the tokens that compose one instruction.
The second LSTM processes the encoded instructions that are produced by the first LSTM.
The output of the second LSTM is aggregated into the final throughput prediction.
